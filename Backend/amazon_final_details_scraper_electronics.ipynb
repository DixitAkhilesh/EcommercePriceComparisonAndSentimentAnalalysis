{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ec0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9b6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_names = []\n",
    "product_urls = []\n",
    "product_prices = []\n",
    "product_reviews = []\n",
    "total_reviews = []\n",
    "product_images = []\n",
    "all_details = []\n",
    "search_input = ''\n",
    "\n",
    "def extractProductName(productUrl,webpage):\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    prod_names = soup.find_all('span',{'class':'a-size-medium a-color-base a-text-normal'})\n",
    "#     print(prod_names)\n",
    "    count = 0\n",
    "    for i in prod_names: \n",
    "        if count < 5:\n",
    "            name = i.text\n",
    "            product_names.append(name);    \n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "#     print(product_names)\n",
    "    \n",
    "    \n",
    "def extractProductUrls(productUrl,webpage):\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    prod_urls = soup.find_all('a',{'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "    count = 0\n",
    "    for i in prod_urls:\n",
    "        if count <5:    \n",
    "            prod_url = i.get(\"href\")  \n",
    "            product_urls.append(\"https://www.amazon.in\" + prod_url)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "#     print(product_urls) \n",
    "    \n",
    "def extractProductPrice(productUrl,webpage):\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    prod_prices = soup.find_all('span',{'class':'a-offscreen'})\n",
    "    count = 0\n",
    "    for i in prod_prices:\n",
    "        if count <5: \n",
    "            prod_price = i.text\n",
    "            product_prices.append(prod_price)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    # print(product_prices) \n",
    "\n",
    "def extractReviews(productUrl,webpage):\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    stars = soup.find_all('span',{'class': 'a-icon-alt'})\n",
    "    num_of_reviews = soup.find_all('span',{'class': 'a-size-base s-underline-text'})\n",
    "    count = 0\n",
    "    for i in stars:\n",
    "        if count < 5:\n",
    "            prod_review = i.text.split()[0]\n",
    "            product_reviews.append(prod_review)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    count1 = 0\n",
    "    for i in num_of_reviews:\n",
    "        if count1<5:\n",
    "            num = i.text\n",
    "            total_reviews.append(num)\n",
    "            count1 += 1\n",
    "        else:\n",
    "            break\n",
    "    # print(product_reviews)\n",
    "    # print(total_reviews)\n",
    "    \n",
    "\n",
    "def extractProductImage(productUrl,webpage):\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.content,\"html.parser\")\n",
    "    prods = soup.find_all('img',{'class':'s-image'})\n",
    "    count = 0\n",
    "    for i in prods:\n",
    "        if count < 5:\n",
    "            prod_img = i.get(\"src\")\n",
    "            product_images.append(prod_img)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    # print(product_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78abf57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter product name: asus vivobook\n",
      "https://www.amazon.in/s?k=asus+vivobook\n",
      "csv_files\\amazon_asus+vivobook.csv\n"
     ]
    }
   ],
   "source": [
    "def main(search_input):\n",
    "    st = search_input.split()\n",
    "    search_input = search_input.replace(\" \", \"+\")\n",
    "    productUrl = \"https://www.amazon.in/s?k=\"+ search_input \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.46','Accept-Language' : 'en-US, en;q=0.5'})\n",
    "    webpage = requests.get(productUrl,headers=HEADERS)\n",
    "    print(productUrl)\n",
    "\n",
    "    extractProductName(productUrl,webpage)\n",
    "    extractProductUrls(productUrl,webpage)\n",
    "    extractProductPrice(productUrl,webpage)\n",
    "    extractReviews(productUrl,webpage)\n",
    "    extractProductImage(productUrl,webpage)\n",
    "\n",
    "    all_details = zip(product_names,product_urls,product_prices,product_reviews,total_reviews,product_images)\n",
    "    \n",
    "    file_name = 'amazon_' +search_input + '.csv'\n",
    "    directory_name = \"csv_files\" \n",
    "    file_path = os.path.join(directory_name, file_name)\n",
    "    print(file_path)\n",
    "    \n",
    "    header = ['Name', 'Link', 'Price', 'Reviews', 'Number of Reviews','Images']\n",
    "    \n",
    "    with open(file_path , 'w', newline='', encoding='utf-8') as file:\n",
    "        # Create a CSV writer object\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        writer.writerow(header)\n",
    "        for row in all_details:\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22077873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
